# Known problems:
#
# The dependency checker system is kind of clunky: we can only toggle/modify
# it globally; it would be better to have some sort of 'instance' based
# system.  (So we can turn it off as needed, or ignore it if it fails, silence
# warnings etc)
#

# ----------------------------------------------------------------------------
# Generic utilities
# -----------------

def update_dict(d0, *dicts, merger=None):
    for d in dicts:
        if merger:
            for k, v in d.items():
                exists = False
                try:
                    v0 = d0[k]
                    exists = True
                except KeyError:
                    pass
                if exists:
                    d0[k] = merger((k, v0), (k, v))[1]
                else:
                    d0[k] = v
        else:
            d0.update(d)

def merge_dicts(*dicts, merger=None):
    d0 = {}
    update_dict(d0, *dicts, merger=merger)
    return d0

def merge_sets(*sets):
    s0 = set()
    for s in sets:
        s0.update(s)
    return s0

def freeze_value(value):
    '''Convert a value into an immutable form with a total ordering.'''
    if isinstance(value, tuple) or isinstance(value, list):
        return tuple(map(freeze_value, value))
    elif isinstance(value, dict):
        return tuple(sorted((k, freeze_value(v)) for k, v in value.items()))
    elif isinstance(value, set) or isinstance(value, frozenset):
        return tuple(sorted(value))
    return value

def exclusive_merge(arg0, *args):
    '''Return one of the arguments if all of them are equal.  Fails with
    `ValueError` otherwise.'''
    for arg in args:
        if arg0 != arg:
            raise ValueError("conflicting values: {0} vs {1}"
                             .format(repr(arg0), repr(arg)))
    return arg0

def merge_frozen_dicts(*dicts):
    '''Merge several dictionaries with the values frozen.  Fails with
    `ValueError` if they have conflicting values for the same key.'''
    return merge_dicts(*(
        dict((k, freeze_value(v))
             for k, v in d.items())
        for d in dicts
    ), merger=exclusive_merge)

# ----------------------------------------------------------------------------
# Hashing
# -------

DEFAULT_HASH_LENGTH = 20

def hash_str(s, length=DEFAULT_HASH_LENGTH):
    import base64, hashlib
    h = hashlib.sha512(s.encode("utf-8")).digest()
    return base64.urlsafe_b64encode(h)[:length].decode("ascii")

def hash_json(data, length=DEFAULT_HASH_LENGTH):
    import json
    s = json.dumps(data, ensure_ascii=False, sort_keys=True)
    return hash_str(s, length=length)

# ----------------------------------------------------------------------------
# Syntactic manipulation
# ----------------------

def shell_quote(string):
    import re
    # we try to be conservative here because some shells have more special
    # characters than others (`!` and `^` are not safe); we require empty
    # strings to be quoted
    if re.match("[]a-zA-Z0-9/@.,_+-]+$", string):
        return string
    return "'{0}'".format(string.replace("'", "'\\''"))

def shell_quote_arg(string):
    import re
    # allow `=` since it's safe as an argument
    if re.match("[]a-zA-Z0-9/@.,_=+-]+$", string):
        return string
    return shell_quote(string)

def make_escape(string):
    return string.replace("$", "$$")

def make_unescape(string):
    return string.replace("$$", "$")

def make_rule_header_lex(string):
    '''This is a simplified lexer that is not faithful to the actual makefile
    syntax (colons and tabs are ignored) but it is sufficient for parsing the
    output of cpp -M.'''
    import re
    token = ""
    escaping = False
    for m in re.finditer(r"([^ \n\\]*)([ \n\\]?)", string):
        s, c = m.groups()
        token += s
        if escaping:
            escaping = False
            if not s:
                if c == "\n":
                    yield token[:-1]
                    token = ""
                else:
                    token += c
                continue
        if c == "\\":
            token += "\\"
            escaping = True
        else:
            if token:
                yield token
                token = ""
            if c == "\n":
                break
    if token:
        yield token

def make_rule_header_parse(string):
    import re
    # ignore the target (btw, this regex is surprisingly robust)
    m = re.match("(?s).*?: (.*)", string)
    if not m:
        raise ValueError("could not parse dependency tool output:\n\n" + string)
    return make_rule_header_lex(m.group(1))

def save_makefile(file, macros_rules, header="# autogenerated\n", posix=True):
    '''
    macros_rules: ({Str: Str, ...},
                   [([Str, ...], [Str, ...], [Str, ...]), ...])
    header: Str
    posix: Bool

    `rules` is a list of triples each containing the targets, prerequisites,
    and commands respectively.
    '''
    macros, rules = macros_rules
    # do some sanity checks to avoid subtle bugs
    for value in macros.values():
        if not isinstance(value, str):
            raise ValueError("macro value must be a str: " +
                             repr(value))
    for targets, prerequisites, commands in rules:
        if isinstance(targets, str):
            raise ValueError("targets must be a list of str, "
                             "not a str: " + repr(targets))
        if isinstance(prerequisites, str):
            raise ValueError("prerequisites must be a list of str, "
                             "not a str: " + repr(prerequisites))
        if isinstance(commands, str):
            raise ValueError("commands must be a list of str, "
                             "not a str: " + repr(commands))
    with open(file, "wt") as stream:
        stream.write(header)
        if posix:
            stream.write(".POSIX:\n")

        for i, (name, value) in enumerate(sorted(macros.items())):
            if i == 0:
                stream.write("\n")
            stream.write("{0}={1}\n".format(name, value))

        for targets, prerequisites, commands in rules:
            stream.write("\n")
            stream.write(" ".join(targets))
            stream.write(":")
            stream.write("".join(" " + x for x in sorted(prerequisites)))
            stream.write("\n")
            stream.write("".join("\t" + x + "\n" for x in commands))

# ----------------------------------------------------------------------------
# Source code dependencies
# ------------------------
#
# A dependency tool is a function that takes the filename of the source file
# and returns a list of filenames that the given source file depends on
# (usually due to a preprocessing mechanism such as `#include`).
#
#     DependencyTool = (Str) -> [Str, ...]

def guess_source_code_language(extension):
    if extension.startswith("."):
        extension = extension[1:]
    if extension == "c":
        return "c"
    if extension in ["cc", "cpp", "cxx", "c++"]:
        return "c++"
    raise ValueError("cannot guess language for ." + extension)

def null_dependency_tool(filename):
    return []

def run_external_dependency_tool(command, filename):
    import os, subprocess, tempfile
    with open(os.devnull, "wb") as fnull, \
         tempfile.NamedTemporaryFile() as out_fn:
        p = subprocess.Popen(command + [out_fn.name, filename],
                             stdin=fnull,
                             stdout=subprocess.PIPE,
                             stderr=subprocess.STDOUT,
                             universal_newlines=True)
        err, _ = p.communicate()
        with open(out_fn.name, "rt") as f:
            out = f.read()
    if p.returncode or not out:
        raise ValueError("failed to run dependency tool for {0}:\n\n{1}"
                         .format(repr(filename), err))
    return sorted(make_rule_header_parse(out))

def check_external_dependency_tool(command, extension):
    import os, subprocess, tempfile
    with open(os.devnull, "wb") as fnull, \
         tempfile.NamedTemporaryFile() as out_fn, \
         tempfile.NamedTemporaryFile(suffix=extension) as in_fn:
        return subprocess.Popen(
            command + [out_fn.name, in_fn.name],
            stdin=fnull,
            stdout=fnull,
            stderr=fnull,
        ).wait() == 0

def guess_default_dependency_tool(language):
    import os
    if language == "c":
        cc = os.environ.get("CC", "cc")
        ext = ".c"
        candidates = [[cc] + std + ["-MG", "-MM", "-MF"] for std in [
            ["-std=c11"],
            ["-std=c99"],
            ["-std=c89"],
            [],
        ]]
    elif language == "c++":
        cxx = os.environ.get("CXX", "c++")
        ext = ".cpp"
        candidates = [[cxx] + std + ["-MG", "-MM", "-MF"] for std in [
            ["-std=c++17"],
            ["-std=c++14"],
            ["-std=c++11"],
            ["-std=c++03"],
            [],
        ]]
    else:
        raise ValueError("unknown language: {0}".format(repr(language)))
    try:
        return next(cmd for cmd in candidates
                    if check_external_dependency_tool(cmd, ext))
    except StopIteration:
        raise Exception("no dependency tool available for {0}"
                        .format(language))

def get_dependency_tool(language):
    if language not in DEPENDENCY_TOOLS:
        return null_dependency_tool
    tool = DEPENDENCY_TOOLS[language]
    if not tool:
        import functools
        tool = functools.partial(
            run_external_dependency_tool,
            guess_default_dependency_tool(language),
        )
        DEPENDENCY_TOOLS[language] = tool
    return tool

'''A dict of dependency tools keyed by language.  This variable may be tweaked
as necessary.'''
DEPENDENCY_TOOLS = {
    "c": None,
    "c++": None,
}

# ----------------------------------------------------------------------------
# Building makefiles
# ------------------

def get_suffixes(inference_rules):
    '''[(Str, *), ...] -> {Str, ...}'''
    import re
    suffixes = set()
    for rule in inference_rules:
        suffixes.update(re.match(r"(\.[^.]+)(\.[^.]+)$", rule[0]).groups())
    return suffixes

def auto_mkdir(commands):
    return ['''@d=`dirname '$@'` && mkdir -p "$$d"'''] + list(commands)

def prettify_rules(rules):
    # regroup rules that are identical in prerequisites and commands
    merged_rules = merge_dicts(*(
        {freeze_value((sorted(prerequisites), commands)): set([target])}
        for target, (prerequisites, commands) in rules.items()
    ), merger=merge_sets)
    return sorted((tuple(sorted(targets)),) + prerequisites_commands
                  for prerequisites_commands, targets in merged_rules.items())

def prettify_inference_rules(inference_rules):
    return sorted(((tuple([target]), (), commands)
                   for target, commands in inference_rules.items()),
                  key=(lambda rule: rule[0]))

def emit_clean_rule(cleans):
    return {"clean": (
        [],
        ["rm -f -r --" + "".join(
            " '{0}'".format(x)
            for x in sorted(cleans)
        )] if cleans else [],
    )}

def emit_makefile(macros, default_target, phonys, rules,
                  inference_rules, special_rules):
    rules = dict(rules)              # make a copy as we're about to modify it
    default_rule = ({} if default_target is None else
                    {default_target: rules.pop(default_target)})
    phony_rules = dict((phony, rules.pop(phony))
                       for phony in phonys if phony in rules)
    return (macros, (
        prettify_rules(default_rule) +
        prettify_rules(phony_rules) +
        prettify_rules(rules) +
        prettify_inference_rules(inference_rules) +
        special_rules
    ))

class Ruleset(object):
    '''The attributes should never be mutated, because they may be shared with
    various other rulesets (for efficiency reasons).  Instead, replace them
    with a copy if you wish to edit them.  Better yet, just make a new
    ruleset.'''

    def __init__(self, rules={}, macros={}, inference_rules={},
                 cleans=None, phonys=set(), default_target=None,
                 hints={}):
        '''
        rules: {Str: ([Str], [Str]), ...}
        macros: {Str: Str, ...}
        inference_rules: {Str: [Str], ...}
        cleans: {Str, ...}
        phonys: {Str, ...}
        default_target: Str | None
        hints: {...}
        '''
        if "clean" in rules:
            raise ValueError("the 'clean' rule is reserved")
        for phony in phonys:
            if phony not in rules:
                raise ValueError("phony target does not exist: " + phony)
        if default_target is None:
            if phonys:
                default_target = min(phonys)
            elif rules:
                default_target = min(rules)
        elif default_target not in rules:
            raise ValueError("invalid default target: " + default_target)
        if cleans is None:
            cleans = set(rules.keys()).difference(phonys)
        self.rules = rules
        self.macros = macros
        self.inference_rules = inference_rules
        self.cleans = cleans
        self.phonys = phonys
        self.default_target = default_target
        self.hints = hints

    def __repr__(self):
        return "Ruleset(\n{0})".format("".join(
            "    {0}={1},\n".format(k, repr(v))
            for k, v in sorted(self.__dict__.items())
        ))

    def merge(self, *others):
        '''Merge several rulesets with the current one and return the result.
        The merge is slightly biased: it will use the default target of the
        this ruleset.'''
        others = [self] + list(others)
        return Ruleset(
            rules=merge_frozen_dicts(*(x.rules for x in others)),
            macros=merge_dicts(*(x.macros for x in others),
                               merger=exclusive_merge),
            inference_rules=merge_frozen_dicts(*(x.inference_rules
                                                 for x in others)),
            cleans=merge_sets(*(x.cleans for x in others)),
            phonys=merge_sets(*(x.phonys for x in others)),
            default_target=self.default_target,
        )

    def copy(self):
        return self.merge()

    def emit(self):
        clean_rule = emit_clean_rule(self.cleans)
        phonys = self.phonys.union(clean_rule.keys())
        suffixes = get_suffixes(self.inference_rules.items())
        return emit_makefile(
            macros=self.macros,
            default_target=self.default_target,
            phonys=phonys,
            rules=merge_frozen_dicts(self.rules, clean_rule),
            inference_rules=self.inference_rules,
            special_rules=[
                ([".SUFFIXES"], sorted(suffixes), []),
                ([".PHONY"], sorted(phonys), []),
            ],
        )

def emit_args(args):
    if isinstance(args, str):
        # fail early to avoid subtle bugs
        raise TypeError("must be a list of str, not a str: " + repr(args))
    return "".join(" " + make_escape(shell_quote_arg(arg)) for arg in args)

def cpp_macros_to_flags(macros):
    return ["-D{0}={1}".format(k, v) for k, v in sorted(macros.items())]

def get_clike_language_info(language):
    if language == "c":
        return "$(CC)", "$(CFLAGS)"
    elif language == "c++":
        return "$(CXX)", "$(CXXFLAGS)"
    else:
        raise ValueError("not a C-like language: {0}".format(repr(language)))

def emit_compile_args(language, args):
    import itertools
    compiler, flags = get_clike_language_info(language)
    return "".join([
        (
            compiler if args["compiler"] is None else
            emit_args(args["compiler"])
        ),
        "" if args["inherit_cppflags"] is None else " $(CPPFLAGS)",
        "" if args["inherit_flags"] is None else " " + flags,
        emit_args(itertools.chain(
            (
                [] if args["standard"] is None else
                ["-std={0}".format(args["standard"])]
            ),
            cpp_macros_to_flags(args["macros"]),
            args["extra_flags"],
        )),
    ])

def compile_source(filename, language=None,
                   detect_dependencies=True, **kwargs):
    import os, logging
    stem, ext = os.path.splitext(filename)
    language = language or guess_source_code_language(ext)
    args = merge_dicts(DEFAULT_ARGS[language], kwargs)
    prereqs = []
    if os.path.isfile(filename):
        try:
            prereqs = get_dependency_tool(language)(filename)
        except Exception as e:
            logging.warn(e)
    else:
        logging.warn("cannot detect dependencies (file does not exist) "
                     "for: {0}".format(filename))
    prereqs.append(filename)
    prereqs = set(prereqs)
    compile_args = emit_compile_args(language, args)
    args_hash = hash_str(compile_args)
    if args_hash == DEFAULT_ARGS_HASH[language]:
        out_stem = stem
        commands = []
        inference_rules = INFERENCE_RULES[language]
    else:
        out_stem = "{0}_{1}".format(stem, args_hash)
        commands = auto_mkdir([
            "{0} -c -o '$@' {1}".format(
                compile_args,
                make_escape(shell_quote(filename)),
            ),
        ])
        inference_rules = {}
    return Ruleset(
        rules={"{0}.o".format(out_stem): (prereqs, commands)},
        inference_rules=inference_rules,
        macros=DEFAULT_MACROS[language],
        hints={"language": language},
    )

def guess_final_language(objs):
    language_rank = {"c": 1, "c++": 2}
    final_language = "c"
    final_rank = language_rank.get(final_language)
    for obj in objs:
        language = obj.hints.get("language", None)
        rank = language_rank.get(language, None)
        if language is None or rank is None:
            return None
        if rank > final_rank:
            final_language = language
            final_rank = rank
    return final_language

def build_program(filename, objs, language=None):
    obj_fns = [obj.default_target for obj in objs]
    if language is None:
        language = guess_final_language(objs)
    if language is None:
        raise ValueError("cannot guess program language")
    compiler, flags = get_clike_language_info(language)
    return Ruleset(
        rules={filename: (
            obj_fns,
            ["{0} {1} -o '$@' {2}".format(
                compiler,
                flags,
                " ".join(
                    make_escape(shell_quote(obj_fn))
                    for obj_fn in obj_fns
                ),
            )],
        )},
        macros=DEFAULT_MACROS[language],
    ).merge(*objs)

INFERENCE_RULES = {
    "c": {".c.o": auto_mkdir([
        "$(CC) $(CPPFLAGS) $(CFLAGS) -c -o '$@' '$<'",
    ])},
    "c++": {".cpp.o": auto_mkdir([
        "$(CXX) $(CPPFLAGS) $(CXXFLAGS) -c -o '$@' '$<'",
    ])},
}

DEFAULT_MACROS = {
    "c": {"CC": "cc"},
    "c++": {"CXX": "c++"},
}

DEFAULT_CLIKE_ARGS = {
    "compiler": None, # or [Str, ...]
    "inherit_cppflags": True,
    "inherit_flags": True,
    "standard": None, # or Str
    "macros": {},
    "extra_flags": [],
}

DEFAULT_ARGS = {
    "c": DEFAULT_CLIKE_ARGS,
    "c++": DEFAULT_CLIKE_ARGS,
}

DEFAULT_ARGS_HASH = dict(
    (language, hash_str(emit_compile_args(language, args)))
    for language, args in DEFAULT_ARGS.items()
)
