<h1>PHY 905 004 HW #6</h1>
<address rel="author">Fei Yuan</address>
<h2>Part 1</h2>
<p>This time, the benchmarks were run on MSU's HPC cluster as a batch job (as opposed to a development node, where there is likely interference from other jobs).  16 cores were reserved by the scheduler.  Each benchmark performs a copy of an array with <code>2<sup>26</sup></code> elements (the size is chosen to be larger than the L3 cache size of 25MiB).  The code is compiled with <code>-O3</code> with GCC 5.2.</p>
<figure>
  <table>
    <tr>
      <td><code>Nt</code></td>
      <td>Time for loop /s</td>
      <td>Rate /(MB/s)</td>
    </tr>
    ${data}
  </table>
  <figcaption>Table 1: Time and rate vs number of threads.</figcaption>
</figure>
<figure>
  <a href="${fig_time_fn}"><img src="${fig_time_fn}"/></a>
  <figcaption>Figure 1: Time vs number of threads.</figcaption>
</figure>
<figure class="page-break-before">
  <pre><code class="c">${code}</code></pre>
  <figcaption>Listing 1: OpenMP-parallelized array copy.</figcaption>
</figure>
<h2>Part 2</h2>
<figure>
  <a href="${fig_rate_fn}"><img src="${fig_rate_fn}"/></a>
  <figcaption>Figure 2: Rate vs number of threads, as well as the fit.</figcaption>
</figure>
<p>We fit the results to the following model:</p>
<p class="equation"><code><var>rate</var> = min(<var>Nt</var> Ã— <var>r</var><sub>1</sub>, <var>r</var><sub>max</sub>)</code></p>
<p>The fit captures the general trend, but is very crude.  The value of <code><var>r</var><sub>1</sub></code>, which is derived from the single-threaded rate, seems overly optimistic.  There is likely a significant amount of contention in multi-threaded programs, so in reality the performance improvement with each additional thread suffers from diminishing returns.  Moreover, as the number of threads increase further, the performance actually becomes worse, possibly from the overhead of managing multiple threads as well as the competition between threads for the limited memory bandwidth.  The crossover point where the memory bandwidth becomes the bottleneck is around 2 to 3 in the model, but the actual data seems to indicate around 5.</p>
