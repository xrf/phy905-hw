<h1>PHY 905 004 HW #2</h1>
<address rel="author">Fei Yuan</address>
<h2>Part 1</h2>
<p>System information:</p>
<ul>
  <li>Intel Core i5-2500K 3.3 GHz (max 4.2 GHz)</li>
  <li>Corsair DDR3 SDRAM 1333 9-9-9-24</li>
  <li>ASUS P8Z68-V/GEN3 LGA 1155</li>
</ul>
<figure>
  <table>
    <tr>
      <td><var>n</var></td>
      <td>Time for loop /s</td>
      <td>Rate /(MB/s)</td>
    </tr>
    ${data}
  </table>
  <figcaption>Table 1: Time taken and rate vs size of array.</figcaption>
</figure>
<figure>
  <a href="fig-time.svg"><img src="fig-time.svg"/></a>
  <figcaption>Figure 1: Time taken vs size of array.</figcaption>
</figure>
<figure>
  <a href="fig-rate.svg"><img src="fig-rate.svg"/></a>
  <figcaption>Figure 2: Rate vs size of array.</figcaption>
</figure>
<figure class="page-break-before">
  <pre><code class="c">${code}</code></pre>
  <figcaption>Listing 1: Code used to perform the benchmarks.</figcaption>
</figure>
<h2 class="page-break-before">Part 2</h2>
<p>The C version was used.  Array size was chosen to be 2<sup>24</sup> elements (128 MiB), which should be more than sufficient since the caches are only a few MiB.</p>
<figure>
  <pre><code class="nohighlight">${report}</code></pre>
  <figcaption>Listing 2: Output from STREAM.</figcaption>
</figure>
<h2>Part 3</h2>
<p>Using the pessimistic model described in the lecture where nothing is being cached at all, we have:</p>
<p class="equation"><code><var>n</var> (4 <var>r</var> + 8 <var>w</var>) + <var>nnz</var> (2 <var>c</var> + 20 <var>r</var>)</code></p>
<p>where <var>r</var> is the time taken to read one byte, <var>w</var> is the time taken to write one byte, and <var>c</var> is the time taken to perform a floating point operation.  For large sparse matrices, the term containing <var>nnz</var> is dominant.  In this case, 2 floating-point operations are performed for every 20-byte reads.  Given a bandwidth of 6770 MB/s, this allows for a maximum of</p>
<p class="equation"><code>6770 MB/s Ã— 2 FLOP / (20 B) = 0.677 GFLOPS</code></p>
